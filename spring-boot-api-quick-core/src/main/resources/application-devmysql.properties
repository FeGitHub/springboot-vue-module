# 生产环境配置
# 数据源配置，请修改为你项目的实际配置
# 数据源 1
spring.datasource.master.jdbc-url=jdbc:mysql://192.168.61.131:3306/test?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai
spring.datasource.master.username=root
spring.datasource.master.password=root
spring.datasource.master.driver-class-name=com.mysql.cj.jdbc.Driver
spring.datasource.master.validationQuery=select 1 
# 数据源 2
spring.datasource.slave.jdbc-url=jdbc:mysql://192.168.61.131:3306/slave?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai
spring.datasource.slave.username=root
spring.datasource.slave.password=root
spring.datasource.slave.driver-class-name=com.mysql.cj.jdbc.Driver
spring.datasource.slave.validationQuery=select 1 
# 服务开启端口
server.port=8085
# sql日志输出
logging.level.com.company.project.master.dao=debug
logging.level.com.company.project.slave.dao=debug
spring.redis.host=192.168.61.131
#Redis服务器连接端口
spring.redis.port=6379
#Redis服务器连接密码（默认为空）
spring.redis.password=123
#连接池最大连接数（使用负值表示没有限制）
spring.redis.jedis.pool.max-active=8
#连接池最大阻塞等待时间（使用负值表示没有限制）
spring.redis.jedis.pool.max-wait=-1
#连接池中的最大空闲连接
spring.redis.jedis.pool.max-idle=8
#连接池中的最小空闲连接
spring.redis.jedis.pool.min-idle=0
#连接超时时间（毫秒）
spring.redis.timeout=30000
#spring项目名
spring.application.name=spring-boot-api-quick-core
#dubbo configuration
dubbo.application.name=dubbo_consumer
dubbo.registry.protocol=zookeeper
dubbo.registry.address=zookeeper://192.168.61.131:2181
# dubbo.application.qosEnable=true  没起作用
# 关闭启动检查 （为了在没有提供者前提下也能启动）
dubbo.reference.com.foo.BarService.check=false
dubbo.reference.check=false
dubbo.consumer.check=false
dubbo.registry.check=false
# 是否关闭 swagger trues是开启  false是关闭，正式环境必须关闭
swagger.onlion=true
#============== kafka ===================
# 指定kafka 代理地址，可以多个
spring.kafka.bootstrap-servers=192.168.61.131:9092
#=============== provider  =======================
spring.kafka.producer.retries=0
# 每次批量发送消息的数量
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432
# 指定消息key和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
#=============== consumer  =======================
# 指定默认消费者group id
#spring.kafka.consumer.group-id=user-log-group
#spring.kafka.consumer.auto-offset-reset=earliest
#spring.kafka.consumer.enable-auto-commit=true
#spring.kafka.consumer.auto-commit-interval=100
# 指定消息key和消息体的编解码方式
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# 是否开启后端跨域
custom.cross.domain=true





